APACHE SPARK WEEK

installing spark:

    -- download windows version from oracle website

    -- move the zip file into a folder c:/tools and unpack it

    -- add to path

        export JAVA_HOME="/c/tools/jdk-11.0.16/"
        export PATH="${JAVA_HOME}/bin:${PATH}"

    -- get hadoop binaries from https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.0

        -- Create a folder (/c/tools/hadoop-3.2.0) and put the files there

                type the following in terminal:

                    HADOOP_VERSION="3.2.0"
                    PREFIX="https://raw.githubusercontent.com/cdarlint/winutils/master/hadoop-${HADOOP_VERSION}/bin/"

                    FILES="hadoop.dll hadoop.exp hadoop.lib hadoop.pdb libwinutils.lib winutils.exe winutils.pdb"

                    for FILE in ${FILES}; do
                    wget "${PREFIX}/${FILE}"
                    done

        -- add to path 

            export HADOOP_HOME="/c/tools/hadoop-3.2.0"
            export PATH="${HADOOP_HOME}/bin:${PATH}"
        
    -- download spark:

        wget https://dlcdn.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz
        tar xzfv spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz

        -- add to path:

            export SPARK_HOME="/c/tools/spark-3.3.0-bin-hadoop3"
            export PATH="${SPARK_HOME}/bin:${PATH}"    


NOTE: if the path doesnt work, go to 'edit system variables' and add it in manually

- PYSPARK_DRIVER_PYTHON
- PYSPARK_PYTHON
    to file path